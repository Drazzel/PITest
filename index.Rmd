---
title: "Untitled"
author: "Drazzel Feliu"
date: "7/2/2019"
output: pdf_document
---
```{r Timer Tracker}
choose_16_8 <- "8.58 seconds"
choose_18_9 <- "23.6 seconds"
choose_20_10 <- "50.56 seconds"
choose_22_11 <- "4 minutes and 56 seconds"
```

```{r, include=FALSE}
rm(list=ls())
library(tidyverse)
library(random)
library(data.table)
library(permutations)
library(spatstat.utils)
```

The first thing is to create enough test data in order to be able to fully reassign control & treatment groups. We'll start with 16 numbered observations, randomize the assignment of treatment, and randomize the outcome variable we intend to test. This will be our base for using randomized treatment assignments and identifying how to perform the permutation inference test primarily.

```{r Test Data}
x <- 22

test <- tibble("obs"=1:x,
               "treatment"=ifelse(randomNumbers(x,0,100,1)>50,1,0),
               "outcome"=randomNumbers(x,0,50,1))

treated <- sum(test$treatment)

test$treatment <- as.numeric(test$treatment)
test$outcome <- as.numeric(test$outcome)
```

We have so far a truly random assignment of treatment and, for the purposes of this exercise strictly, a random series of outcomes. We can identify the treatment effect by taking the means of the two groups.

```{r Sample Mean}
test %>% group_by(treatment) %>% tally()
test %>% group_by(treatment) %>% summarize(mean=mean(outcome))
```

Let's presume some limitation, that does not allow us to retest this experiment. We can determine whether the outcome was statistically significant by reassigning treatment and control through each permutation, developing a series of means, and then testing our true mean against the artificial means in a distribution and identifying where it landed. 

It's important to note that our random treatment assignment resulted in 9 control observation and 7 treatment observations. In reassigning our treatments again, we need to keep that same balance of 9 control to 7 treatment. For 16 observations, this would result in the following number of possibilities: 11440

```{r Combinations Math}

comb <- function(n,r) {
  num <- factorial(n)
  den1 <- factorial(r)
  den2 <- factorial(n-r)
  return(num/(den1*den2))
}

comb(x,treated)
```


```{r Treatment Reassignment}
perm <- as_tibble(combn(x, treated))
perm_assign <- function (x){ifelse(test$obs %in% x,1,0)}
perm <- as.data.frame(lapply(perm,perm_assign))

colnames(perm) <- paste0("perm_",1:ncol(perm))


#find the perm assignment that matches the original treatment assignment

colmatch <- function(n){identical(test$treatment,n)}

consistencycheck <- as.data.frame(lapply(perm,colmatch))

#--------------

# This part below will be easy to find the matching permutated assignment with the real assignment
consistencycheck[2,] <- colnames(consistencycheck)
consistencycheck <- as.data.frame(transpose(consistencycheck))
consistencycheck <- consistencycheck %>% filter(V1=="TRUE")
```

```{r Generating Distribution}
# merge the data sets

matrix <- cbind(test,perm)

# group by and calculate the sample means (11440 test cases * 2 group means = 22880 observations)
# need to scale this process to 11440 operations

mean_generator <- function(x){as.data.frame(tapply(matrix$outcome, x, mean))}

perm_distro <- as.data.frame(lapply(matrix[c(2,4:ncol(matrix))],mean_generator))

perm_distro <- as.data.frame(transpose(perm_distro))
perm_distro$name <- colnames(matrix[c(2,4:ncol(matrix))])

perm_distro$diff <- perm_distro$V2-perm_distro$V1

actualtreatment <- unlist(perm_distro %>% filter(name=="treatment") %>% select(diff))

perm_distro <- perm_distro  %>%  filter(name!="treatment")
```

```{r Significance Testing}
percentile <- ecdf(perm_distro$diff)(actualtreatment)*100

stat_range <- c(ecdf(perm_distro$diff)(-2*sd(perm_distro$diff))*100,ecdf(perm_distro$diff)(2*sd(perm_distro$diff))*100)

one_tailed <- unlist(quantile(perm_distro$diff,.95,type = 3))

quantile(perm_distro$diff,percentile/100,type = 3)==actualtreatment

two_tailed_test <- ifelse(check.in.range(percentile,stat_range, fatal = FALSE)==TRUE,"Not Significant","Significant")

one_tailed_test <- ifelse(percentile > 95,"Significant","Not Significant")
```

```{r Visual Distribution}
perm_distro %>% filter(name!="treatment") %>% ggplot(.,aes(diff)) + geom_histogram(bins=75) +
  geom_vline(xintercept=mean(perm_distro$diff),
  color="blue") + geom_vline(xintercept = -2*sd(perm_distro$diff), color="green") + 
  geom_vline(xintercept = 2*sd(perm_distro$diff),color="green") + geom_vline(xintercept = actualtreatment, linetype="dashed", color="red") + 
  geom_vline(xintercept = one_tailed, color="black")
```

Attempted Regression

```{r}
reg <- lm(outcome~treatment, test)
summary(reg)
```
